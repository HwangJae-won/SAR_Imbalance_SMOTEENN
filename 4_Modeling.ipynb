{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from classifier_SMOTEENN_local import SMOTEENNBaggingClassifier #modified module is in the local directory\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train = pd.read_csv('trainDF_rdkit.csv', index_col = 'smiles_parent')\n",
    "Test = pd.read_csv('testDF_rdkit.csv', index_col = 'smiles_parent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropping redundant features: (7683, 2378)\n",
      "After dropping redundant features: (7683, 2082)\n"
     ]
    }
   ],
   "source": [
    "y_train = Train.iloc[:,:12].astype('float32')\n",
    "X_train = Train.iloc[:,12:]\n",
    "print('Before dropping redundant features: {}'.format(X_train.shape))\n",
    "\n",
    "y_test = Test.iloc[:,:12].astype('float32')\n",
    "X_test = Test.iloc[:,12:]\n",
    "\n",
    "X_train = X_train.drop(X_train.std()[(X_train.std() == 0)].index, axis=1) #Remove columns where all values are the sames\n",
    "X_test = X_test[X_test.columns.intersection(X_train.columns)].values #Discard columns from Test that are not in Train\n",
    "\n",
    "X_train_cols = X_train.columns.values #get columns for feature importance\n",
    "X_train = X_train.values\n",
    "print('After dropping redundant features: {}'.format(X_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2082,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scale = StandardScaler().fit(X_train)\n",
    "#X_train = scale.transform(X_train)\n",
    "#X_test = scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "fbeta_scorer = make_scorer(fbeta_score, beta=1.5) #vary beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.ensemble import BalancedBaggingClassifier \n",
    "#from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "#class SMNClassifier(BalancedBaggingClassifier):\n",
    "#    sampling_strategy=SMOTEENN()\n",
    "\n",
    "num_est = range(5,101,5)\n",
    "param_grid = {'base_estimator__n_estimators':num_est, \"base_estimator__max_depth\": [1, 3, 5, None], \n",
    "              \"base_estimator__max_features\": [\"auto\", \"log2\", None, 0.5, 0.2], \n",
    "              \"base_estimator__min_samples_leaf\": [0.5, 0.3, 0.1], \"base_estimator__criterion\": [\"gini\", \"entropy\"]}\n",
    "cv = StratifiedKFold(5)\n",
    "res_table = []\n",
    "for target in y_train.columns:\n",
    "    print(target)\n",
    "    rows_tr = np.isfinite(y_train[target]).values\n",
    "    rows_te = np.isfinite(y_test[target]).values\n",
    "\n",
    "    iX_train = X_train[rows_tr, :]\n",
    "    iy_train = y_train[target][rows_tr]\n",
    "    iX_test = X_test[rows_te, :]\n",
    "    iy_test = y_test[target][rows_te]\n",
    "\n",
    "    X_train_, X_test_, y_train_, y_test_ = iX_train, iX_test, iy_train, iy_test\n",
    "    \n",
    "    #--------------------------------------------------\n",
    "    bbc = GridSearchCV(BalancedBaggingClassifier(base_estimator = RandomForestClassifier(), sampling_strategy=SMOTEENN()), \n",
    "                       param_grid, scoring = fbeta_scorer, n_jobs = -1, cv = cv)\n",
    "    \n",
    "    #bbc = RandomizedSearchCV(BalancedBaggingClassifier(base_estimator = RandomForestClassifier()), param_grid, scoring = 'f1', n_iter= 25)\n",
    "    \n",
    "    #Also try n_estimators = imb_ratio\n",
    "    bbc.fit(X_train_, y_train_)\n",
    "    #--------------------------------------------------------------------------\n",
    "    y_pred = bbc.predict_proba(X_test_)\n",
    "    y_pred_ = bbc.predict(X_test_)\n",
    "    #------------------------------------------------------------------\n",
    "    res = []\n",
    "    res.append(target)\n",
    "    \n",
    "    cm = metrics.confusion_matrix(y_test_, y_pred_); print(cm)\n",
    "    TN = cm[0][0]\n",
    "    FN = cm[1][0]\n",
    "    TP = cm[1][1]\n",
    "    FP = cm[0][1]\n",
    "    res.extend([TP, FN, TN, FP]) # extend appends multiple elements, append takes only one\n",
    "    \n",
    "    prec = metrics.precision_score(y_test_, y_pred_); print(\"Precision: {0:.4f}\".format(prec)); res.append(prec)\n",
    "    recall = metrics.recall_score(y_test_, y_pred_); print(\"Recall: {0:.4f}\".format(recall)); res.append(recall)\n",
    "    F1 = metrics.f1_score(y_test_, y_pred_); print(\"f1-Score: {0:.4f}\".format(F1)); res.append(F1)\n",
    "    MCC = metrics.matthews_corrcoef(y_test_, y_pred_); print(\"MCC: {0:.4f}\".format(MCC)); res.append(MCC)\n",
    "    \n",
    "    auroc = metrics.roc_auc_score(y_test_, y_pred[:, 1]); print(\"AUROC Score: {0:.4f}\".format(auroc)); res.append(auroc)\n",
    "    auprc = metrics.average_precision_score(y_test_, y_pred[:, 1]); print(\"AUPRC Score: {0:.4f}\".format(auprc)); res.append(auprc)\n",
    "    brier = metrics.brier_score_loss(y_test_, y_pred[:, 1]); print(\"Brier Score: {0:.4f}\".format(brier)); res.append(brier)\n",
    "    res_table.append(res)\n",
    "    print('-----------------------------------------------------')\n",
    "\n",
    "resDF = pd.DataFrame(res_table, columns = ['Target', 'TP', 'FN', 'TN', 'FP', 'Precision', 'Recall', 'F1-Score', 'MCC',\n",
    "                                          'AUROC', 'AUPRC', 'brier'])\n",
    "#resDF.to_csv('Results/SMOTEENN_recall.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#QUICK CHECK: Effect of varying probability threshold on CM\n",
    "'''\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "f1_scores = []\n",
    "for cutoff in np.arange(0.1,1.0,0.1):\n",
    "    print('Cut-Off: ', cutoff)\n",
    "    y_pred_cut = (y_pred[:,1] > cutoff).astype(int)\n",
    "    f1_cut = metrics.f1_score(y_test_, y_pred_cut)\n",
    "    f1_scores.append(f1_cut)\n",
    "    #-------------------------------------------------\n",
    "    cm = metrics.confusion_matrix(y_test_, y_pred_cut); print(cm)\n",
    "    prec = metrics.precision_score(y_test_, y_pred_cut); print(\"Precision: {0:.2f}\".format(prec))\n",
    "    recall = metrics.recall_score(y_test_, y_pred_cut); print(\"Recall: {0:.2f}\".format(recall))\n",
    "    av_prec = metrics.average_precision_score(y_test_, y_pred_cut); print(\"Av_Precision: {0:.2f}\".format(av_prec))\n",
    "    F1 = metrics.f1_score(y_test_, y_pred_cut); print(\"f1-Score: {0:.2f}\".format(F1))\n",
    "    print('----------------------------')\n",
    "    #--------------------------\n",
    "    #sns.scatterplot(f1_scores, names = np.arange(0.1,0.9,0.1))\n",
    "plt.scatter(np.arange(0.1,1.0,0.1), f1_scores)\n",
    "#plt.title('F-score')\n",
    "#plt.title('Cut-off')\n",
    "plt.show()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
